{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH_LCOmXrrDD"
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras as keras\n",
        "#import tensorflow as tensorflow"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxyKy7aK8sQh",
        "outputId": "41502585-e949-46a5-970f-59788e71294d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQHeEhq49HQX"
      },
      "source": [
        "/content/drive/MyDrive/Colab Notebooks/CS 6304 - Deep Learning/Midterm/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiLReQuVCXVp"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhBQwFgvCagT"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/CS 6304 - Deep Learning/Midterm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHvYkJRCrrDJ"
      },
      "source": [
        "import os\n",
        "directory_path = os.getcwd()\n",
        "print(\"My current directory is : \" + directory_path)\n",
        "folder_name = os.path.basename(directory_path)\n",
        "print(\"My directory name is : \" + folder_name)\n",
        "\n",
        "\n",
        "os.chdir('C:/Users/jdmey/Documents/Deep Learning/Mid Term')\n",
        "\n",
        "directory_path = os.getcwd()\n",
        "print(\"My current directory is : \" + directory_path)\n",
        "folder_name = os.path.basename(directory_path)\n",
        "print(\"My directory name is : \" + folder_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSGVRnKKrrDL"
      },
      "source": [
        "train_class=pd.read_csv('train01.csv',header=None,names=['class','file'])\n",
        "train_class.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJue82wRrrDM"
      },
      "source": [
        "test_class=pd.read_csv('C:/Users/jdmey/Documents/Deep Learning/Mid Term/test01.csv',header=None,names=['class','file'])\n",
        "test_class.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llrUhVVUrrDM"
      },
      "source": [
        "from os import listdir\n",
        "from skimage import io\n",
        "imagedir='train/'\n",
        "files=listdir(imagedir)\n",
        "import numpy as np\n",
        "#creating numpy matrix/tensor to store the images\n",
        "x_train = np.empty(shape=(len(files),28,28),dtype=np.int)\n",
        "#creating numpy matrix to store class labels\n",
        "y_train = np.empty(shape=(len(files)),dtype=np.int)\n",
        "for i in range(0,len(files)):\n",
        "    if(i%2000 == 0):\n",
        "        print('done processing ' + str(i) + ' images')\n",
        "    I = io.imread(imagedir+files[i])\n",
        "    x_train[i,:,:] = I\n",
        "    y_train[i] = train_class.loc[train_class['file'] == files[i],'class'].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwgNLyJ0rrDN"
      },
      "source": [
        "imagedir='test/'\n",
        "files=listdir(imagedir)\n",
        "import numpy as np\n",
        "#creating numpy matrix/tensor to store the images\n",
        "x_test = np.empty(shape=(len(files),28,28),dtype=np.int)\n",
        "#creating numpy matrix to store class labels\n",
        "y_test = np.empty(shape=(len(files)),dtype=np.int)\n",
        "for i in range(0,len(files)):\n",
        "    if(i%2000 == 0):\n",
        "        print('done processing ' + str(i) + ' images')\n",
        "    I = io.imread(imagedir+files[i])\n",
        "    x_test[i,:,:] = I\n",
        "    y_test[i] = test_class.loc[test_class['file'] == files[i],'class'].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln50FqY0rrDO"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCcM-eLhrrDP"
      },
      "source": [
        "x_train1=np.reshape(x_train,(12665,28*28))\n",
        "x_test1=np.reshape(x_test,(2115,28*28))\n",
        "print(x_train1.shape)\n",
        "print(x_test1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD_6J47nrrDP"
      },
      "source": [
        "x_train1 = x_train1/255\n",
        "x_test1 = x_test1/255\n",
        "print(np.max(x_train1))\n",
        "print(np.max(x_test1))\n",
        "print(np.min(x_train1))\n",
        "print(np.min(x_test1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kofCarmArrDQ"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "NB_CLASSES = 2 #number of classes\n",
        "print('shape of y_train and y_test before categorical')\n",
        "y_train_original=y_train\n",
        "y_test_original=y_test\n",
        "print(y_train_original.shape)\n",
        "print(y_test_original.shape)\n",
        "y_train= np_utils.to_categorical(y_train_original, NB_CLASSES)\n",
        "y_test= np_utils.to_categorical(y_test_original, NB_CLASSES)\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "print('shape of y_train and y_test after categorical')\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpkLR8lwrrDR"
      },
      "source": [
        "print(y_train[0,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AjQNh5prrDS"
      },
      "source": [
        "print(y_train[2,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-HcUe8arrDS"
      },
      "source": [
        "from tensorflow.keras.models import Sequential # what kind of model ? a sequenctial model\n",
        "from tensorflow.keras.layers import Dense, Activation # different layers, activation function, and dropout\n",
        "from tensorflow.keras.optimizers import SGD # optimization algorithm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEnptHb4rrDT"
      },
      "source": [
        "NB_EPOCH = 150 # number of epoch\n",
        "BATCH_SIZE = 30 # mini batch size\n",
        "VERBOSE = 1 #display results during training\n",
        "NB_CLASSES = 10 #number of classes\n",
        "OPTIMIZER = keras.optimizers.Adam(learning_rate=0.01) # choose optimizer\n",
        "N_HIDDEN = 1 # number of nodes in the hidden layer\n",
        "VALIDATION_SPLIT = 0.2 #80% training and 20%validation\n",
        "METRICS =['accuracy']\n",
        "LOSS = 'categorical_crossentropy' # because of multiclass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af3_lAN4rrDT"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN,input_shape=(x_train1.shape[1],),activation='relu'))\n",
        "model.add(Dense(NB_CLASSES,activation='softmax'))\n",
        "print(model.summary()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnMtzcDOrrDT"
      },
      "source": [
        "model.compile(loss=LOSS, optimizer = 'adam', metrics =METRICS)\n",
        "Tuning = model.fit(x_train1,y_train,batch_size=BATCH_SIZE, epochs = NB_EPOCH, verbose = VERBOSE,\n",
        "                   validation_split = VALIDATION_SPLIT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmJV559mrrDU"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "def plotHistory(Tuning):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    axs[0].plot(Tuning.history['loss'])\n",
        "    axs[0].plot(Tuning.history['val_loss'])\n",
        "    axs[0].set_title('loss vs epoch')\n",
        "    axs[0].set_ylabel('loss')\n",
        "    axs[0].set_xlabel('epoch')\n",
        "    axs[0].legend(['train', 'vali'], loc='upper left')\n",
        "    \n",
        "    axs[1].plot(Tuning.history['accuracy']) \n",
        "    axs[1].plot(Tuning.history['val_accuracy'])\n",
        "    axs[1].set_title('accuracy vs epoch')\n",
        "    axs[1].set_ylabel('accuracy')\n",
        "    axs[1].set_xlabel('epoch')\n",
        "    axs[1].legend(['train', 'vali'], loc='upper left')\n",
        "    plt.show(block = False)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}